{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'last'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.33\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Datastore\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.tensorboard import Tensorboard\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training models using Azure Machine Learning\n",
    "\n",
    "In this notebook, instead of running the training script manually in a VM, we make use of the Azure Machine Learning (AML) Python SDK to run our experiments.\n",
    "\n",
    "See the official [tutorial](https://docs.microsoft.com/en-us/azure/machine-learning/service/tutorial-train-models-with-aml) covering this set-up with a sci-kit learn example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to AML workspace\n",
    "\n",
    "Refer to [Create a Azure Machine Learning service workspace](https://docs.microsoft.com/en-us/azure/machine-learning/service/setup-create-workspace) for how to create an AML workspace in Azure Portal or using the Python SDK or the Azure CLI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "siyu\twestus2\tyasiyu_rg\twestus2\n"
     ]
    }
   ],
   "source": [
    "# load workspace configuration from the config.json file in the current folder.\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, ws.location, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or attach an existing compute resource\n",
    "\n",
    "Documentation on [AmlCompute.provisioning_configuration](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.amlcompute%28class%29?view=azure-ml-py#provisioning-configuration-vm-size-----vm-priority--dedicated---min-nodes-0--max-nodes-none--idle-seconds-before-scaledown-none--admin-username-none--admin-user-password-none--admin-user-ssh-key-none--vnet-resourcegroup-name-none--vnet-name-none--subnet-name-none--tags-none--description-none-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found compute target and will be using it: gpu-cluster\n"
     ]
    }
   ],
   "source": [
    "# choose a name for your cluster\n",
    "compute_name = 'gpu-cluster'\n",
    "compute_min_nodes = 1\n",
    "compute_max_nodes = 2\n",
    "idle_seconds = 120\n",
    "\n",
    "# for ssh into individual node to debug\n",
    "admin_username='username'\n",
    "admin_user_password='password'\n",
    "\n",
    "\n",
    "vm_size = 'STANDARD_NC6'  # Choose a GPU SKU that is available in your subscription's AML quota (separate from main VM quota) and region\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('Found compute target and will be using it: ' + compute_name)\n",
    "else:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
    "                                                                min_nodes=compute_min_nodes, \n",
    "                                                                max_nodes=compute_max_nodes,\n",
    "                                                                idle_seconds_before_scaledown=idle_seconds,\n",
    "                                                                admin_username=admin_username,\n",
    "                                                                admin_user_password=admin_user_password)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to datastore\n",
    "\n",
    "[Documentation](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-access-data)\n",
    "\n",
    "In this demonstration, we stored all training data preprocessed using the SpaceNet utilities in a container on Azure Blob Storage. This allows us to mount the container on VMs or instances of AML clusters like the one we connected to above. To use AML, you have to have your data stored in the cloud (either Blob Storage or File Share) in order for the compute resource to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "storage_account_name = os.environ.get('STORAGE_ACCOUNT_NAME')\n",
    "storage_account_key = os.environ.get('STORAGE_ACCOUNT_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azureml.data.azure_storage_datastore.AzureBlobDatastore object at 0x1166d9fd0>\n",
      "<azureml.data.azure_storage_datastore.AzureBlobDatastore object at 0x11674f128>\n"
     ]
    }
   ],
   "source": [
    "input_data_store_name = 'dataprocessed'\n",
    "output_data_store_name = 'models'\n",
    "\n",
    "# in my set-up, the input data and output models are in two containers under the same storage account\n",
    "input_container_name = 'data-processed'\n",
    "output_container_name = 'models'\n",
    "\n",
    "input_data_store = None\n",
    "output_data_store = None\n",
    "for name, ds in ws.datastores.items():\n",
    "    if name == input_data_store_name:\n",
    "        input_data_store = ds\n",
    "    if name == output_data_store_name:\n",
    "        output_data_store = ds\n",
    "        \n",
    "if input_data_store is None:\n",
    "    'Input datastore {} is not in the workspace; registering it...'.format(input_data_store_name)\n",
    "    input_data_store = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                             datastore_name=input_data_store_name, \n",
    "                                             container_name=input_container_name,\n",
    "                                             account_name=storage_account_name, \n",
    "                                             account_key=storage_account_key,\n",
    "                                             create_if_not_exists=True)\n",
    "\n",
    "if output_data_store is None:\n",
    "    'Output datastore {} is not in the workspace; reigstering it...'.format(output_data_store_name)\n",
    "    output_data_store = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                             datastore_name=output_data_store_name, \n",
    "                                             container_name=output_container_name,\n",
    "                                             account_name=storage_account_name, \n",
    "                                             account_key=storage_account_key,\n",
    "                                             create_if_not_exists=True)\n",
    "\n",
    "print(input_data_store)\n",
    "print(output_data_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an AML experiment\n",
    "In each AML workspace we can have multiple experiments, and each experiment can have multiple runs. You can use experiments to organize your project/workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_name = 'baseline'\n",
    "\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the estimator to submit a run\n",
    "\n",
    "An estimator object is used to submit a run of the experiment. \n",
    "\n",
    "More information on the PyTorch class of the AML Estimator is [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-train-pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    '--experiment_name': experiment_name,\n",
    "    '--data_path_root': input_data_store,\n",
    "    '--out_dir': output_data_store,\n",
    "    '--num_epochs': 1\n",
    "}\n",
    "\n",
    "pt_est = PyTorch(source_directory='../training',  # this folder gets copied from your local machine to the remote compute\n",
    "                 script_params=script_params,\n",
    "                 compute_target=compute_target,\n",
    "                 entry_script='train_aml.py',  # relative to source_directory\n",
    "                 pip_packages=['scikit-image', 'tensorflow==1.9.0'],  # there's also a conda_packages option\n",
    "                 use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# submit the PyTorch job\n",
    "run = exp.submit(pt_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read more on what happens when you submit a job, see [Monitor a remote run](https://docs.microsoft.com/en-us/azure/machine-learning/service/tutorial-train-models-with-aml#monitor-a-remote-run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Run.get_details of Run(Experiment: baseline,\n",
       "Id: baseline_1557850469_10634baa,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Queued)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://MacBook-Pro-6.local:6006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://MacBook-Pro-6.local:6006'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Tensorboard constructor takes an array of runs\n",
    "tb = Tensorboard([run])\n",
    "\n",
    "# If successful, start() returns a string with the URI of the instance.\n",
    "tb.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# when done, call the stop() method of the Tensorboard object, or it will stay running even after your job completes.\n",
    "# tb.stop()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
